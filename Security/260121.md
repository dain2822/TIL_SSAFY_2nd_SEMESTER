### 생성형 AI 기술과 정보 보안

- Deep Fake 기술을 활용한 피싱에 적극 활용되고 있는 상황(AI로 탐지 가능)
- AI는 보안 위협을 빠르게 찾고 노동집약적인 작업을 대체
    - 비정상 텍스트 감지
    - 스팸 및 피싱 메일 차단을 위한 AI는 이미 사용 중이며, 빅테크 기업들도 보안 AI 분야에서 경쟁 중임
    - 이상 행위 탐지, 악성 코드 탐지 및 분석, 자동화된 위협 대응 등 보안 시스템 전반에 AI 기술이 빠르게 접목되고 있음
    - AI 사용 시 보안 취약점 스캔과 필터링 역량을 대폭 강화

### 통계로 보는 AI 기반 공격 현황

**악당의 무기가 된 AI로 자동 협상부터 해킹까지**

| 지표 | 수치 |
| --- | --- |
| 딥페이크 음성 사기 증가율 | 전년 대비 1,300% 증가(25년 6월 기준) |
| AI 피싱 이메일 및 계정 탈취 피싱 증가율 | 2024년 하반기 전년 대비 202%, 703% 증가 |
| 연간 AI 공격 건수 | 전세계 2,800만 건 이상 |
| AI 데이터 침해 평균 피해액 | 평균 572만 달러(약 79억 원) |

### 24년 7월, 페라리 CEO 사칭

**딥페이크 사기 미수 사건**

- 페라리 임원이 딥페이크 사기의 표적이 된 사건
- 사기꾼은 AI를 이용해 페라리 CEO를 사칭하고 거래에 대한 도움을 요청
- 표적이 된 사람은 “신원을 확인해야 합니다”라고 반박하며 CEO에게 며칠 전에 추천했던 책에 대해 묻는 방식으로 대응

### AI를 활용한 공격이 가능한 시대

**악성코드를 생성하는 Worm GPT**

- WormGPT가 다크웹에서 판매되고 있음
    - 다크웹 : 전용 소프트웨어로 접속할 수 있는 웹 서비스로 익명성이 보장되어 마약 거래, 불법 개인정보 매매 등 음성적 활동이 가능한 웹 서비스
- 간단한 명령으로 특정 취약점을 노린 해킹 코드나 도구를 생성
    - 공격의 극단적 일반화
    - 랜섬웨어도 손쉽게 생성 가능
- 공격 도구 생성 비용 절감에 따른 해킹 시도 급증

### AI를 이용한 공격 자동화

**이미 인간의 속도로 대응이 불가능한 수준에 도달**

- 중국 배우 해커조직인 GTG-1002이 Claude Code를 악용해 공격 코드를 생성
- 전체 작업 대부분(8-90% 추정)을 AI로 자동화하고 마지막 최종 승인만 사람이 개입

### Google Sec-PaLM

**악성 스크립트의 활동을 분석해 위협 판단**

- 주요 기능
    - 악성 스크립트 분석 및 설명
    - 구글이 보유한 위협 데이터(Mandiant, Virus Total 등)를 학습하여 악성 코드의 행동, 위협 지표, 해커 그룹의 프로필 등을 분석하는 데 활용
        - 보안 침해 사고가 발생 시 공격 경로를 분석 복잡한 위협을 요약하여 즉각적인 대응 조치를 제안하는 등 보안 업무를 자동화
    - 비전문가도 위협을 탐지하고 대응할 수 있도록 지원

### Copilot for Security

**자연어 대화형 인터페이스 기반 보안 업무보조**

- 주요 기능
    - 자연어 기반 대화형 인터페이스를 이용해 복잡한 보안 데이터에 대한 분석 결과를 쉽게 접근
    - MS사 생태계 전반에서 수집된 대규모 데이터를 바탕으로 위협 인텔리전스 제공(84조개 이상의 일일 보안 신호)
    - 보안 운영 실무자의 분석 및 관리 업무 지원에 특화

### 사이버 보안 빅데이터 센터

**다양한 산업에서 수집된 사이버 위협 정보를 분석하고 공유**

### **ChatGPT에 입력한 내용은 학습 데이터로 활용됨**

**23년, S전자 ChatGPT 오남용**

- 반도체 설비 계측, 수율, 불량 등에 관한 프로그램 내용이 미국 기업의 학습 데이터로 입력된 사건
- 반도체 설비 계측 DB 다운로드 프로그램의 오류를 확인하고자 임직원이 소스코드 전부를 ChatGPT에 입력해 해결 방법 문의

### 서비스형 LLM 작동 구조

**→ 민감 데이터 입력 절대 금지!**

→ 무료 LLM 서비스 활용 시 입력하는 모든 정보는 AI 학습 데이터로 활용된다는 사실을 명확히 인지

- 업무 자료를 개인적으로 활용하는 것은 금물!

→ 업무를 위해 LLM 서비스 사용 시 반드시 기업용으로 제한된 환경에서만 사용

### Agentic AI 보안 문제

**Agentic AI가 당신의 PC를 통제한다면?**

| 위험 요소 | 설명 |
| --- | --- |
| 과도한 권한 부여 | 지나친 외부 시스템 접근 권한을 부여할 경우 피해 발생 시 범위가 확대 |
| 프롬프트 인젝션 | 악의적 입력으로 Agent의 행동을 조작 |
| 연쇄 오류 | 현 단계 이후 작업에 연쇄적인 영향을 미침 |
| 데이터 유출 | AI 스스로 민감정보를 외부로 전송 |
| 불병확한 책임 소재 | AI가 판단하고 실행한 결과가 야기한 법적 책임에 대한 처리 |
| Shadow AI | 인가되지 않은 직원이 AI 도구 사용 |
- 상상 가능한 보안 위협 시나리오 #1
    - 악의적 행위자가 Agentic AI를 활용해 타겟 기업 직원들의 SNS, LinkedIn, 공개 게시물을 자동 수집, 분석
        - AI 에이전트는 각 직원의 가족 관계, 취미, 최근 관심사를 파악
        - 개인별 맞춤형 피싱 메일을 대량 생성
    - 기존에는 한 명을 집중 공략했다면 AI는 수백 명의 직원에게 각각 다른 맥락의 정교한 피싱 메일을 동시에 발송
- 상상 가능한 보안 위협 시나리오 #2
    - 기획팀 김 과장은 일상적 업무의 생산성을 극대화하고자 AI 에이전트에게 다양한 시스템 접근 권한 부여를 한 상황
    - “사내 공유 폴더에서 필요한 자료를 찾아오고, ERP에서 데이터를 뽑아서 보고서 만들어줘.”라는 명령에 대해 AI는 김 과장의 계정으로 여러 시스템에 자유롭게 접근
    - 김 과장의 PC가 피싱 메일로 감염된 후 해커는 AI 에이전트에게 부여된 광범위한 시스템 접근 권한을 그대로 활용해 시스템 공격
- 상상 가능한 보안 위협 시나리오 #3
    - 마케팅팀 이 주임은 경쟁사 분석을 위해 AI 에이전트를 활용하기로 결정
    - “이 URL 목록에 있는 페이지들 전부를 열어서 내용 요약해줘.”라는 명령에 AI는 수십 개의 URL을 자동으로 방문
    - 그 중 하나가 해커가 만들어둔 악성 사이트였고 AI 에이전트가 해당 페이지를 열자마자 브라우저 취약점을 통해 악성코드가 설치

### Agentic AI 보안 원칙

**권한 통제, 모니터링, 승인 절차 필수**

| 원칙 | 내용 |
| --- | --- |
| 최소 권한 원칙 | 작업에 필요한 최소한의 권한만 부여 |
| Human in the loop | 중요 결정은 사람의 확인 후 실행 |
| 샌드박스 실행 | 격리된 환경(가상 컴퓨팅 환경)에서 테스트
특정 폴더에 대해서만 접근 권한 부여 |
| 행동 로깅 | 에이전트 활동 기록 및 감사 |
| 입/출력 필터링 | 민감정보 포함 여부 실시간 검사 |
| 시간 및 횟수 제한 | 과도한 API 호출 방지 |

### 기술적 인프라 구축

**기업 수준에서 AI 활용을 직접 통제**

- Private AI, 프라이버시 강화 기술, DLP
- API 게이트웨이
    - 입력 정보 필터링 시스템
    - 기존 API 게이트웨이 확장 혹은 서드파티 솔루션 도입
- 단순 접근 차단
    - 보안성을 높일 수 있으나 AI가 제공하는 생산성을 포기

## 디지털 인증 기술과 SSL

### 대표적인 Hash 알고리즘

- MD-5 : 패스워드 단방향 암호화에서 사용금지
- SHA-1
- SHA-128, 256, 384, 512

**대표적인 Hash 기술 활용 예**

- 무결성 확보
    - 인증서 검증
    - 디지털 포렌식
    - 디지털 서명(Hash + PKI)
- 패스워드 단방향 암호화
- 블록체인